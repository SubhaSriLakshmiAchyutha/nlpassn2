{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d6adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat: Precision = 0.250, Recall = 0.250\n",
      "Dog: Precision = 0.444, Recall = 0.444\n",
      "Rabbit: Precision = 0.400, Recall = 0.400\n",
      "\n",
      "Macro-averaged Precision = 0.365\n",
      "Macro-averaged Recall = 0.365\n",
      "\n",
      "Micro-averaged Precision = 0.389\n",
      "Micro-averaged Recall = 0.389\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Confusion matrix from the problem:\n",
    "# Rows = system predictions, Cols = gold labels\n",
    "confusion_matrix = np.array([\n",
    "    [5, 10, 5],   # Predicted Cat\n",
    "    [15, 20, 10], # Predicted Dog\n",
    "    [0, 15, 10]   # Predicted Rabbit\n",
    "])\n",
    "\n",
    "# Class labels\n",
    "classes = [\"Cat\", \"Dog\", \"Rabbit\"]\n",
    "\n",
    "# Step 1: Compute per-class precision & recall\n",
    "row_sums = confusion_matrix.sum(axis=1)  # predicted totals\n",
    "col_sums = confusion_matrix.sum(axis=0)  # gold totals\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for i, label in enumerate(classes):\n",
    "    TP = confusion_matrix[i, i]\n",
    "    FP = row_sums[i] - TP\n",
    "    FN = col_sums[i] - TP\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    \n",
    "    print(f\"{label}: Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
    "\n",
    "# Step 2: Macro-averaging\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "print(f\"\\nMacro-averaged Precision = {macro_precision:.3f}\")\n",
    "print(f\"Macro-averaged Recall = {macro_recall:.3f}\")\n",
    "\n",
    "# Step 3: Micro-averaging\n",
    "TP_total = np.trace(confusion_matrix)       # sum of diagonal\n",
    "FP_total = row_sums.sum() - TP_total\n",
    "FN_total = col_sums.sum() - TP_total\n",
    "\n",
    "micro_precision = TP_total / (TP_total + FP_total)\n",
    "micro_recall = TP_total / (TP_total + FN_total)\n",
    "\n",
    "print(f\"\\nMicro-averaged Precision = {micro_precision:.3f}\")\n",
    "print(f\"Micro-averaged Recall = {micro_recall:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0296b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unigram Counts ===\n",
      "      </s>: 3\n",
      "       <s>: 3\n",
      "         I: 2\n",
      "       NLP: 1\n",
      "      deep: 2\n",
      "       fun: 1\n",
      "        is: 1\n",
      "  learning: 2\n",
      "      love: 2\n",
      "\n",
      "=== Bigram Counts ===\n",
      "(       <s>, I         ) : 2\n",
      "(       <s>, deep      ) : 1\n",
      "(         I, love      ) : 2\n",
      "(       NLP, </s>      ) : 1\n",
      "(      deep, learning  ) : 2\n",
      "(       fun, </s>      ) : 1\n",
      "(        is, fun       ) : 1\n",
      "(  learning, </s>      ) : 1\n",
      "(  learning, is        ) : 1\n",
      "(      love, NLP       ) : 1\n",
      "(      love, deep      ) : 1\n",
      "\n",
      "=== Bigram Probabilities (MLE) ===\n",
      "P(I|<s>) = 0.666667\n",
      "P(deep|<s>) = 0.333333\n",
      "P(love|I) = 1.000000\n",
      "P(</s>|NLP) = 1.000000\n",
      "P(learning|deep) = 1.000000\n",
      "P(</s>|fun) = 1.000000\n",
      "P(fun|is) = 1.000000\n",
      "P(</s>|learning) = 0.500000\n",
      "P(is|learning) = 0.500000\n",
      "P(NLP|love) = 0.500000\n",
      "P(deep|love) = 0.500000\n",
      "\n",
      "=== Sentence Probabilities ===\n",
      "S1: <s> I love NLP </s> -> P = 0.333333, logP = -1.098612\n",
      "S2: <s> I love deep learning </s> -> P = 0.166667, logP = -1.791759\n",
      "\n",
      "Preferred Sentence: S1\n",
      "\n",
      "Probability of S1 = 0.3333 Probability of S2 = 0.1667 Under the bigram MLE model, S1 has the higher probability because the sequence “love → NLP” followed by “NLP → </s>” matches the training data more strongly than “love → deep → learning → </s>”.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import tee\n",
    "import math\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Training corpus\n",
    "# ----------------------------\n",
    "corpus = [\n",
    "    [\"<s>\", \"I\", \"love\", \"NLP\", \"</s>\"],\n",
    "    [\"<s>\", \"I\", \"love\", \"deep\", \"learning\", \"</s>\"],\n",
    "    [\"<s>\", \"deep\", \"learning\", \"is\", \"fun\", \"</s>\"],\n",
    "]\n",
    "\n",
    "def bigrams(tokens):\n",
    "    a, b = tee(tokens)\n",
    "    next(b, None)\n",
    "    return list(zip(a, b))\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Unigram & bigram counts\n",
    "# ----------------------------\n",
    "unigram_counts = Counter()\n",
    "bigram_counts = Counter()\n",
    "for sent in corpus:\n",
    "    unigram_counts.update(sent)\n",
    "    bigram_counts.update(bigrams(sent))\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Bigram MLE: P(w_i | w_{i-1}) = c(w_{i-1}, w_i) / c(w_{i-1})\n",
    "# ----------------------------\n",
    "def bigram_mle_prob(w_prev, w_cur):\n",
    "    c_prev = unigram_counts[w_prev]\n",
    "    c_bigram = bigram_counts.get((w_prev, w_cur), 0)\n",
    "    if c_prev == 0:\n",
    "        return 0.0\n",
    "    return c_bigram / c_prev\n",
    "\n",
    "# Optional: pretty table (dict of dicts)\n",
    "cond_probs = {}\n",
    "for (w_prev, w_cur), c in bigram_counts.items():\n",
    "    cond_probs.setdefault(w_prev, {})[w_cur] = c / unigram_counts[w_prev]\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Sentence probability (MLE bigram)\n",
    "#    Returns (prob, log_prob); zero if any unseen bigram\n",
    "# ----------------------------\n",
    "def sentence_prob(tokens):\n",
    "    logp = 0.0\n",
    "    for w_prev, w_cur in bigrams(tokens):\n",
    "        p = bigram_mle_prob(w_prev, w_cur)\n",
    "        if p == 0.0:\n",
    "            return 0.0, float(\"-inf\")\n",
    "        logp += math.log(p)\n",
    "    return math.exp(logp), logp\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Test the two sentences\n",
    "# ----------------------------\n",
    "s1 = [\"<s>\", \"I\", \"love\", \"NLP\", \"</s>\"]\n",
    "s2 = [\"<s>\", \"I\", \"love\", \"deep\", \"learning\", \"</s>\"]\n",
    "\n",
    "p1, lp1 = sentence_prob(s1)\n",
    "p2, lp2 = sentence_prob(s2)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Print results\n",
    "# ----------------------------\n",
    "print(\"=== Unigram Counts ===\")\n",
    "for tok, cnt in sorted(unigram_counts.items()):\n",
    "    print(f\"{tok:>10}: {cnt}\")\n",
    "\n",
    "print(\"\\n=== Bigram Counts ===\")\n",
    "for (w_prev, w_cur), cnt in sorted(bigram_counts.items()):\n",
    "    print(f\"({w_prev:>10}, {w_cur:<10}) : {cnt}\")\n",
    "\n",
    "print(\"\\n=== Bigram Probabilities (MLE) ===\")\n",
    "for w_prev in sorted(cond_probs):\n",
    "    for w_cur in sorted(cond_probs[w_prev]):\n",
    "        print(f\"P({w_cur}|{w_prev}) = {cond_probs[w_prev][w_cur]:.6f}\")\n",
    "\n",
    "print(\"\\n=== Sentence Probabilities ===\")\n",
    "print(f\"S1: {' '.join(s1)} -> P = {p1:.6f}, logP = {lp1:.6f}\")\n",
    "print(f\"S2: {' '.join(s2)} -> P = {p2:.6f}, logP = {lp2:.6f}\")\n",
    "\n",
    "preferred = \"S1\" if p1 > p2 else \"S2\" if p2 > p1 else \"Tie\"\n",
    "print(f\"\\nPreferred Sentence: {preferred}\")\n",
    "print(f\"\\nProbability of S1 = 0.3333 Probability of S2 = 0.1667 Under the bigram MLE model, S1 has the higher probability because the sequence “love → NLP” followed by “NLP → </s>” matches the training data more strongly than “love → deep → learning → </s>”.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118be22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
